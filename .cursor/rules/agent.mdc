---
globs: agent/**/*.ts
alwaysApply: false
---
# LangGraph Agent Flow Documentation

## Flow Overview

The agent processes tasks through the following sequential stages:

1. **Start** → Index Codebase
2. **Index Codebase** → Setup Sandbox (on success) OR End (on failure)
3. **Setup Sandbox** → Plan Changes (on success) OR End (on failure)
4. **Plan Changes** → Edit Files (on success) OR End (on failure)
5. **Edit Files** → Create PR (on success) OR End (on failure)
6. **Create PR** → End

## Node Specifications

### 1. INDEX CODEBASE NODE

**Purpose**: Clone repository and create/update searchable index using Merkle tree for efficient incremental updates

**Inputs**:
- `task`: User task description
- `repoUrl`: Repository URL to clone
- `baseBranch`: Base branch to work from
- `previousMerkleRoot`: Previous Merkle tree root hash (from MySQL)

**Processing**:
1. Clone repository from repoUrl
2. **Merkle Tree Construction**:
   - Compute cryptographic hash for each valid code file
   - Build Merkle tree from file hashes (leaf nodes)
   - Combine hashes hierarchically to compute root hash
   - Store Merkle tree structure in MySQL for persistence
3. **Determine Indexing Scope**:
   - If no previous Merkle root exists → Index entire codebase
   - If previous root exists → Compare with current root
   - If roots match → Skip indexing (codebase unchanged)
   - If roots differ → Identify changed files via tree traversal
4. **Chunking Strategy** (for files requiring indexing):
   - Parse files using AST (Abstract Syntax Tree) for semantic boundaries
   - Split code into meaningful chunks (functions, classes, modules)
   - Respect token limits (e.g., 8192 for embeddings)
   - Preserve semantic context within chunks
5. **Embedding Generation**:
   - Generate embeddings using Vercel AI SDK
   - Create vector representations for each chunk
   - Include metadata: file path, line numbers, chunk hash
6. **Storage**:
   - Store embeddings in Qdrant vector database
   - Store Merkle tree and file hashes in MySQL
   - Cache embeddings indexed by chunk hash for reuse

**Outputs**:
- `indexedFiles`: Array of IndexedFile objects (only newly indexed/changed files)
- `merkleRoot`: Current Merkle tree root hash
- `changedFiles`: Array of file paths that changed since last index
- `isVectorDatabaseReady`: Boolean flag
- `currentStep`: 'indexing_complete' or 'indexing_failed'

**State Updates**:
- Populates indexedFiles with only changed/new files
- Updates merkleRoot in state and MySQL
- Sets isVectorDatabaseReady to true on success
- Stores Merkle tree structure for future comparisons
- Adds error to errors array on failure

**Incremental Update Benefits**:
- Avoids re-indexing unchanged files
- Reduces bandwidth and processing time
- Enables efficient caching of embeddings
- Supports team collaboration with shared index

---

### 2. SETUP SANDBOX NODE

**Purpose**: Create isolated Vercel Sandbox environment with Git-enabled repository access

**Inputs**:
- `repoUrl`: Repository URL (supports private repos)
- `baseBranch`: Base branch to checkout
- `indexedFiles`: Files from indexing stage
- GitHub App credentials (from env):
  - `GITHUB_APP_ID`
  - `GITHUB_APP_PRIVATE_KEY`
- Authentication: VERCEL_OIDC_TOKEN or (VERCEL_TOKEN + VERCEL_TEAM_ID + VERCEL_PROJECT_ID)

**Processing**:
1. Generate GitHub App installation access token
2. Initialize Vercel Sandbox with configuration:
   - Source: Git repository with authentication
   - Resources: vCPUs (1-8), memory allocation
   - Runtime: 'node22' or 'python3.13'
     - Node 22 runtime at `/vercel/runtimes/node22`
     - Python 3.13 runtime at `/vercel/runtimes/python`
   - Timeout: 5-45 minutes (default 5 minutes)
   - Ports: Array of ports to expose (e.g., [3000])
3. Clone repository into sandbox with GitHub App authentication:
   ```javascript
   source: {
     url: repoUrl,
     type: 'git',
     username: 'x-access-token',
     password: githubAppToken
   }
   ```
4. Configure Git identity for Pullsmith app:
   - Set git user.name to "Pullsmith[bot]"
   - Set git user.email to appropriate GitHub App email
5. Checkout the specified baseBranch
6. Install project dependencies if needed

**Outputs**:
- `sandboxId`: Unique identifier for sandbox instance
- `sandboxInstance`: Sandbox SDK instance for operations
- `isSandboxReady`: Boolean flag
- `currentStep`: 'sandbox_ready' or 'sandbox_failed'

**State Updates**:
- Sets sandboxId for subsequent file operations
- Stores sandboxInstance for command execution
- Sets isSandboxReady to true on success
- Adds error to errors array on failure

**Technical Details**:
- Sandbox runs on Amazon Linux 2023 base
- Default working directory: `/vercel/sandbox`
- User: `vercel-sandbox` with sudo access
- Sudo configuration:
  - HOME set to `/root` (sources root config files)
  - PATH unchanged (keeps local/project binaries)
  - Environment variables inherited
- Pre-installed packages include: git, openssl, tar, unzip, etc.
- Can install packages via `dnf` package manager
- Commands executed via `sandbox.runCommand()`:
  - Supports `detached: true` for long-running processes
  - Can stream stdout/stderr to process streams
- Public URLs accessible via `sandbox.domain(port)` method
- Sandbox can be stopped via `sandbox.stop()` method

---

### 3. PLAN CHANGES NODE

**Purpose**: Analyze task and create implementation plan using semantic search

**Inputs**:
- `task`: User task description
- `indexedFiles`: Indexed code files (from current session)
- `isVectorDatabaseReady`: Database ready flag
- `merkleRoot`: Current codebase state identifier

**Processing**:
1. **Query Embedding Generation**:
   - Convert task description into embedding using Vercel AI SDK
   - Create semantic representation of the user's intent
2. **Semantic Search**:
   - Query Qdrant vector database with task embedding
   - Perform nearest-neighbor search to find relevant code chunks
   - Retrieve top-k most semantically similar code sections
3. **Context Assembly**:
   - Collect relevant code chunks with metadata (file paths, line ranges)
   - Read full content of identified files from indexedFiles
   - Build comprehensive context of related code patterns
4. **Plan Generation with LLM**:
   - Use assembled context with Cursor-style system prompt
   - Generate structured implementation plan
   - Consider existing code patterns and conventions
   - Prioritize changes based on dependencies
5. **Action Item Creation**:
   - Break down plan into specific file modifications
   - Maintain consistency with existing codebase style
   - Include rationale for each proposed change

**Outputs**:
- `relevantFiles`: Array of file paths relevant to task
- `semanticMatches`: Code chunks with similarity scores
- `plan`: Array of PlanItem objects with actions
- `currentStep`: 'planning_complete' or 'planning_failed'

**State Updates**:
- Populates relevantFiles with identified files
- Stores semantic search results for reference
- Creates detailed plan with prioritized actions
- Adds error to errors array on failure

**Semantic Search Benefits**:
- Finds conceptually related code, not just text matches
- Understands code context and relationships
- Maintains codebase consistency and patterns
- Enables intelligent refactoring suggestions

---

### 4. EDIT FILES NODE

**Purpose**: Execute planned changes to code files in Vercel Sandbox

**Inputs**:
- `plan`: Array of PlanItem objects
- `indexedFiles`: Original file contents
- `sandboxId`: Sandbox environment identifier
- `sandboxInstance`: Sandbox SDK instance

**Processing**:
1. Sort plan items by priority
2. For each plan item:
   - Read current file content from sandbox
   - Generate new content using LLM
   - Apply changes (modify/create/delete) in sandbox
   - Execute via `sandboxInstance.runCommand()` or file operations
3. Validate syntax and basic functionality:
   - Run linting/formatting commands if configured
   - Execute type checking for TypeScript projects
4. Optionally run tests or build commands:
   - Use `detached: true` for long-running processes
   - Stream output to monitor progress
5. Stage all changes using git add

**Outputs**:
- `editedFiles`: Array of EditedFile objects
- `isEditingComplete`: Boolean flag
- `currentStep`: 'editing_complete' or 'editing_failed'

**State Updates**:
- Populates editedFiles with original and new content
- Sets isEditingComplete to true on success
- Adds error to errors array on failure

**Sandbox Operations**:
- File operations via Sandbox SDK file system methods
- Command execution with proper error handling
- Support for streaming output during builds/tests
- Ability to run development servers for validation

---

### 5. CREATE PR NODE

**Purpose**: Create git branch and pull request using GitHub App within sandbox

**Inputs**:
- `editedFiles`: Modified file contents (already in sandbox)
- `repoUrl`: Repository URL
- `baseBranch`: Base branch for PR
- `task`: Original task description
- `sandboxId`: Sandbox environment identifier
- `sandboxInstance`: Sandbox SDK instance
- GitHub App credentials (from env)

**Processing within Sandbox**:
1. Generate unique branch name (e.g., `pullsmith/feature-${timestamp}`)
2. Create and checkout new branch:
   ```bash
   git checkout -b pullsmith/feature-${timestamp}
   ```
3. Commit changes with Pullsmith attribution:
   ```bash
   git commit -m "feat: ${task_summary}" -m "Automated changes by Pullsmith based on task: ${task}"
   ```
4. Push branch to remote using GitHub App token:
   ```bash
   git push origin pullsmith/feature-${timestamp}
   ```
5. Create pull request via GitHub API:
   - Title: Clear summary of changes
   - Body: Detailed description including task context
   - Author: Pullsmith[bot]
   - Base: baseBranch
   - Head: new feature branch
6. Stop sandbox using `sandboxInstance.stop()`

**Outputs**:
- `branchName`: Created branch name
- `commitHash`: Git commit hash
- `prUrl`: Pull request URL
- `currentStep`: 'pr_created' or 'pr_failed'

**State Updates**:
- Sets branchName for reference
- Sets commitHash for tracking
- Sets prUrl for access
- Adds error to errors array on failure

**Git Configuration**:
- All commits authored by "Pullsmith[bot]"
- Uses GitHub App authentication for push operations
- PR created via GitHub API with App credentials

## Sandbox Lifecycle Management

### Initialization
- Sandboxes are created with specific resource allocations (vCPUs)
- Each sandbox has a unique ID and public URLs via `domain(port)`
- Authentication handled via OIDC tokens or manual credentials

### Runtime Management
- Commands can run attached or detached (`detached: true`)
- Output streams can be piped to process.stdout/stderr
- Long-running processes (dev servers) run in background
- File system operations available through SDK methods

### Cleanup
- Sandboxes automatically stop after timeout (5-45 minutes)
- Can be manually stopped via `sandboxInstance.stop()`
- All resources are cleaned up on termination

### Observability
- Monitor sandboxes via Vercel dashboard Observability tab
- View command history and sandbox URLs
- Track compute usage across projects
- Access logs and execution details

### Best Practices
- Always stop sandboxes when work is complete
- Use appropriate timeouts for expected workload
- Stream logs for debugging during development
- Monitor resource usage to optimize costs

## Error Handling

Each node can fail, which will:
- Update `currentStep` to the corresponding failed state
- Add descriptive error message to the `errors` array
- Terminate the flow and proceed to End

## State Transitions

The agent maintains state throughout the flow using the `AgentState` interface, with each node reading required inputs and updating relevant outputs. The `currentStep` field tracks progress and allows for resumption or debugging of failed flows.

## Merkle Tree Indexing Strategy

Inspired by [Cursor's codebase indexing approach](https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast), Pullsmith uses Merkle trees for efficient incremental indexing:

### How It Works

1. **Initial Indexing**:
   - Compute hash for each file in the repository
   - Build Merkle tree with file hashes as leaf nodes
   - Store root hash and tree structure in MySQL
   - Generate embeddings for all files using Vercel AI SDK
   - Store embeddings in Qdrant vector database

2. **Incremental Updates**:
   - On subsequent runs, compute new Merkle tree
   - Compare new root hash with stored root hash
   - If identical: Skip indexing (no changes)
   - If different: Traverse tree to find changed files
   - Only re-index and embed changed files

3. **Storage Architecture**:
   - **MySQL**: Stores Merkle tree structure, file hashes, and metadata
   - **Qdrant**: Stores embeddings with chunk metadata
   - **Cache**: Embeddings indexed by chunk hash for reuse

### Key Benefits

- **Efficiency**: Only changed files are re-indexed
- **Bandwidth Optimization**: Minimal data transfer
- **Team Collaboration**: Shared index across team members
- **Data Integrity**: Cryptographic verification of file states
- **Scalability**: Handles large codebases efficiently

```mermaid
graph TD
    A["Start"] --> B["Index Codebase<br/>• Clone repository<br/>• Build Merkle tree<br/>• Generate embeddings<br/>• Store in Qdrant"]
    
    B --> C{"Indexing<br/>Successful?"}
    C -->|Success| D["Setup Sandbox<br/>• Create Vercel Sandbox<br/>• Configure Git identity<br/>• Install dependencies"]
    C -->|Failure| E["End<br/>(Indexing Failed)"]
    
    D --> F{"Sandbox<br/>Ready?"}
    F -->|Success| G["Plan Changes<br/>• Semantic search<br/>• Query embeddings<br/>• Generate plan<br/>• Create action items"]
    F -->|Failure| H["End<br/>(Sandbox Failed)"]
    
    G --> I{"Planning<br/>Complete?"}
    I -->|Success| J["Edit Files<br/>• Execute plan items<br/>• Modify/create files<br/>• Validate syntax<br/>• Stage changes"]
    I -->|Failure| K["End<br/>(Planning Failed)"]
    
    J --> L{"Editing<br/>Complete?"}
    L -->|Success| M["Create PR<br/>• Create branch<br/>• Commit changes<br/>• Push to remote<br/>• Create pull request<br/>• Stop sandbox"]
    L -->|Failure| N["End<br/>(Editing Failed)"]
    
    M --> O{"PR Created<br/>Successfully?"}
    O -->|Success| P["End<br/>(Success)"]
    O -->|Failure| Q["End<br/>(PR Failed)"]
    
    style A fill:#e1f5fe
    style P fill:#e8f5e8
    style E fill:#ffebee
    style H fill:#ffebee
    style K fill:#ffebee
    style N fill:#ffebee
    style Q fill:#ffebee
```